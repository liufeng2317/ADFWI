{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "import sys\n",
    "import os\n",
    "from ADFWI.propagator  import *\n",
    "from ADFWI.model       import *\n",
    "from ADFWI.view        import *\n",
    "from ADFWI.utils       import *\n",
    "from ADFWI.survey      import *\n",
    "from ADFWI.fwi         import *\n",
    "from ADFWI.dip         import *\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "project_path = \"/ailab/user/liufeng1/project/04_Inversion/ADFWI-github/examples/pip_usage/data/\"\n",
    "if not os.path.exists(os.path.join(project_path,\"model\")):\n",
    "    os.makedirs(os.path.join(project_path,\"model\"))\n",
    "if not os.path.exists(os.path.join(project_path,\"waveform\")):\n",
    "    os.makedirs(os.path.join(project_path,\"waveform\"))\n",
    "if not os.path.exists(os.path.join(project_path,\"survey\")):\n",
    "    os.makedirs(os.path.join(project_path,\"survey\"))\n",
    "if not os.path.exists(os.path.join(project_path,\"inversion-DIP\")):\n",
    "    os.makedirs(os.path.join(project_path,\"inversion-DIP\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the basic model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"         # Specify the GPU device\n",
    "dtype = torch.float32     # Set data type to 32-bit floating point\n",
    "ox, oz = 0, 0             # Origin coordinates for x and z directions\n",
    "nz, nx = 88, 200          # Grid dimensions in z and x directions\n",
    "dx, dz = 40, 40           # Grid spacing in x and z directions\n",
    "nt, dt = 1600, 0.003      # Time steps and time interval\n",
    "nabc = 30                 # Thickness of the absorbing boundary layer\n",
    "f0 = 5                    # Initial frequency in Hz\n",
    "free_surface = True       # Enable free surface boundary condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the initial velocity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Marmousi model dataset from the specified directory.\n",
    "marmousi_model = load_marmousi_model(in_dir=\"/ailab/user/liufeng1/project/04_Inversion/ADFWI-github/examples/datasets/marmousi2_source\")\n",
    "\n",
    "# Create coordinate arrays for x and z based on the grid size.\n",
    "x = np.linspace(5000, 5000 + dx * nx, nx)\n",
    "z = np.linspace(0, dz * nz, nz)\n",
    "true_model = resample_marmousi_model(x, z, marmousi_model)\n",
    "smooth_model = get_smooth_marmousi_model(true_model, gaussian_kernel=6)\n",
    "\n",
    "# Initialize primary wave velocity (vp) and density (rho) for the model.\n",
    "vp_init = smooth_model['vp'].T  # Transpose to match dimensions\n",
    "rho_init = np.power(vp_init, 0.25) * 310  # Calculate density based on vp\n",
    "\n",
    "# Extract true model properties for comparison.\n",
    "vp_true = true_model['vp'].T  # Transpose for consistency\n",
    "rho_true = np.power(vp_true, 0.25) * 310  # Calculate true density\n",
    "\n",
    "# -----------------------------------\n",
    "#     Define DIP model\n",
    "# -----------------------------------\n",
    "layer_num = 3\n",
    "base_channel = 64\n",
    "model_shape = [nz,nx]\n",
    "DIP_model = DIP_Unet(model_shape,\n",
    "                        n_layers= layer_num,\n",
    "                        vmin=vp_true.min()/1000,\n",
    "                        vmax=vp_true.max()/1000,\n",
    "                        base_channel=base_channel,\n",
    "                        device=device)\n",
    "DIP_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "#     Pretrain DIP model\n",
    "# -----------------------------------\n",
    "pretrain        = True\n",
    "load_pretrained = False\n",
    "if pretrain:\n",
    "    if load_pretrained:\n",
    "        # load the model parameters\n",
    "        DIP_model.load_state_dict(torch.load(os.path.join(project_path,f\"inversion-DIP/DIP_model_pretrained.pt\")))\n",
    "    else:\n",
    "        lr          = 0.005\n",
    "        iteration   = 10000\n",
    "        step_size   = 1000\n",
    "        gamma       = 0.5\n",
    "        optimizer = torch.optim.Adam(DIP_model.parameters(),lr = lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=gamma)\n",
    "        vp_init = numpy2tensor(vp_init,dtype=dtype).to(device)\n",
    "        pbar = tqdm(range(iteration+1))\n",
    "        for i in pbar:  \n",
    "            vp_nn = DIP_model()\n",
    "            loss = torch.sqrt(torch.sum((vp_nn - vp_init)**2))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            pbar.set_description(f'Pretrain Iter:{i}, Misfit:{loss.cpu().detach().numpy()}')\n",
    "        torch.save(DIP_model.state_dict(),os.path.join(project_path,f\"inversion-DIP/DIP_model_pretrained.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "#     velocity model for FWI\n",
    "# -----------------------------------\n",
    "grad_mask = np.ones((vp_init.shape[0],vp_init.shape[1]))\n",
    "grad_mask[:10,:] = 0\n",
    "model = DIP_AcousticModel(ox,oz,nx,nz,dx,dz,\n",
    "                        DIP_model,\n",
    "                        vp_init=vp_init,rho_init=rho_init,\n",
    "                        gradient_mask=grad_mask,\n",
    "                        gradient_mute=None,\n",
    "                        free_surface=free_surface,\n",
    "                        abc_type=\"PML\",abc_jerjan_alpha=0.007,\n",
    "                        nabc=nabc,\n",
    "                        device=device,dtype=dtype)\n",
    "print(model.__repr__())\n",
    "model.save(os.path.join(project_path,\"model/init_model.npz\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the observed systems: Survey = Source + Receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source positions in the model\n",
    "src_z = np.array([1 for i in range(2, nx-1, 5)])  # Z-coordinates for sources\n",
    "src_x = np.array([i for i in range(2, nx-1, 5)])  # X-coordinates for sources\n",
    "\n",
    "# Generate wavelet for the source\n",
    "src_t, src_v = wavelet(nt, dt, f0, amp0=1)  # Create time and wavelet amplitude\n",
    "src_v = integrate.cumtrapz(src_v, axis=-1, initial=0)  # Integrate wavelet to get velocity\n",
    "\n",
    "source = Source(nt=nt, dt=dt, f0=f0)  # Initialize source object\n",
    "\n",
    "# Method 1: Add multiple sources at once (commented out)\n",
    "# source.add_sources(src_x=src_x, src_z=src_z, src_wavelet=src_v, src_type='mt', src_mt=np.array([[1,0,0],[0,1,0],[0,0,1]]))\n",
    "\n",
    "# Method 2: Loop through each source position to add them individually\n",
    "for i in range(len(src_x)):\n",
    "    source.add_source(src_x=src_x[i], src_z=src_z[i], src_wavelet=src_v, src_type=\"mt\", src_mt=np.array([[1,0,0],[0,1,0],[0,0,1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define receiver positions in the model\n",
    "rcv_z = np.array([1 for i in range(0, nx, 1)])  # Z-coordinates for receivers\n",
    "rcv_x = np.array([j for j in range(0, nx, 1)])  # X-coordinates for receivers\n",
    "\n",
    "receiver = Receiver(nt=nt, dt=dt)  # Initialize receiver object\n",
    "\n",
    "# Method 1: Add all receivers at once (commented out)\n",
    "# receiver.add_receivers(rcv_x=rcv_x, rcv_z=rcv_z, rcv_type='pr')\n",
    "\n",
    "# Method 2: Loop through each receiver position to add them individually\n",
    "for i in range(len(rcv_x)):\n",
    "    receiver.add_receiver(rcv_x=rcv_x[i], rcv_z=rcv_z[i], rcv_type=\"pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a survey object using the defined source and receiver\n",
    "survey = Survey(source=source, receiver=receiver)\n",
    "\n",
    "# Print a representation of the survey object to check its configuration\n",
    "print(survey.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the wavelet used in the source\n",
    "source.plot_wavelet(save_path=os.path.join(project_path, \"survey/wavelets.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the survey configuration over the velocity model\n",
    "survey.plot(model.vp,cmap='coolwarm',save_path=os.path.join(project_path,\"survey/observed_system_init.png\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the propagator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the wave propagator using the specified model and survey configuration\n",
    "F = AcousticPropagator(model, survey, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the damping array from the propagator and plot it to visualize boundary conditions\n",
    "damp = F.damp\n",
    "plot_damp(damp,save_path=os.path.join(project_path,\"model/boundary_condition.png\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load observed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of SeismicData using the survey object.\n",
    "d_obs = SeismicData(survey)\n",
    "\n",
    "# Load observed waveform data from a specified file.\n",
    "d_obs.load(os.path.join(project_path, \"waveform/obs_data.npz\"))\n",
    "\n",
    "# Print a summary representation of the observed seismic data.\n",
    "print(d_obs.__repr__())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "#                   Waveform Propagator\n",
    "#------------------------------------------------------\n",
    "F = AcousticPropagator(model,survey,device=device)\n",
    "damp = F.damp\n",
    "plot_damp(damp,save_path=os.path.join(project_path,\"model/boundary_condition_init.png\"),show=False)\n",
    "\n",
    "# load data\n",
    "d_obs = SeismicData(survey)\n",
    "d_obs.load(os.path.join(project_path,\"waveform/obs_data.npz\"))\n",
    "print(d_obs.__repr__())\n",
    "\n",
    "# optimizer\n",
    "iteration   =   10\n",
    "optimizer   =   torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler   =   torch.optim.lr_scheduler.StepLR(optimizer,step_size=100,gamma=0.75,last_epoch=-1)\n",
    "\n",
    "# Setup misfit function\n",
    "from ADFWI.fwi.misfit import Misfit_global_correlation\n",
    "loss_fn = Misfit_global_correlation(dt=1)\n",
    "\n",
    "# gradient processor\n",
    "grad_mask = np.ones((vp_init.shape[0],vp_init.shape[1]))\n",
    "grad_mask[:10,:] = 0\n",
    "gradient_processor = GradProcessor(grad_mask=grad_mask)\n",
    "\n",
    "# gradient processor\n",
    "fwi = DIP_AcousticFWI(propagator=F,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    loss_fn=loss_fn,\n",
    "                    obs_data=d_obs,\n",
    "                    gradient_processor=gradient_processor,\n",
    "                    waveform_normalize=True,\n",
    "                    cache_result=True,\n",
    "                    save_fig_epoch=50,\n",
    "                    save_fig_path=os.path.join(project_path,f\"inversion-DIP\")\n",
    "                    )\n",
    "\n",
    "fwi.forward(iteration=iteration,batch_size=None,checkpoint_segments=1)\n",
    "\n",
    "iter_vp     = fwi.iter_vp\n",
    "iter_loss   = fwi.iter_loss \n",
    "np.savez(os.path.join(project_path,f\"inversion-DIP/iter_vp.npz\"),data=np.array(iter_vp))\n",
    "np.savez(os.path.join(project_path,f\"inversion-DIP/iter_loss.npz\"),data=np.array(iter_loss))\n",
    "torch.save(model.DIP_model.state_dict(),os.path.join(project_path,f\"inversion-DIP/DIP_model.pt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the inverted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the misfit\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(iter_loss,c='k')\n",
    "plt.xlabel(\"Iterations\", fontsize=12)\n",
    "plt.ylabel(\"L2-norm Misfits\", fontsize=12)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.savefig(os.path.join(project_path,\"inversion-DIP/misfit.png\"),bbox_inches='tight',dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the initial model and inverted resutls\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(vp_init,cmap='jet_r')\n",
    "plt.subplot(122)\n",
    "plt.imshow(iter_vp[-1],cmap='jet_r')\n",
    "plt.savefig(os.path.join(project_path,\"inversion-DIP/inverted_res.png\"),bbox_inches='tight',dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set up the figure for plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cax = ax.imshow(iter_vp[0], aspect='equal', cmap='jet_r', vmin=vp_true.min(), vmax=vp_true.max())\n",
    "ax.set_title('Inversion Process Visualization')\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Z Coordinate')\n",
    "\n",
    "# Create a horizontal colorbar\n",
    "cbar = fig.colorbar(cax, ax=ax, orientation='horizontal', fraction=0.046, pad=0.2)\n",
    "cbar.set_label('Velocity (m/s)')\n",
    "\n",
    "# Adjust the layout to minimize white space\n",
    "plt.subplots_adjust(top=0.85, bottom=0.2, left=0.1, right=0.9)\n",
    "\n",
    "# Initialization function\n",
    "def init():\n",
    "    cax.set_array(iter_vp[0])  # Use the 2D array directly\n",
    "    return cax,\n",
    "\n",
    "# Animation function\n",
    "def animate(i):\n",
    "    cax.set_array(iter_vp[i])  # Update with the i-th iteration directly\n",
    "    return cax,\n",
    "\n",
    "# Create the animation\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init, frames=len(iter_vp), interval=100, blit=True)\n",
    "\n",
    "# Save the animation as a video file (e.g., MP4 format)\n",
    "ani.save(os.path.join(project_path, \"inversion-DIP/inversion_process.gif\"), writer='pillow', fps=10)\n",
    "\n",
    "# Display the animation using HTML\n",
    "plt.close(fig)  # Prevents static display of the last frame\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADinversion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e52d0fb768956d75c9106cc9d1e4cd93f3049c3ef5ccf93d433f27b0d7ebb6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
